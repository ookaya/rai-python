{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained Optimization\n",
    "\n",
    "All methods to compute paths or configurations solve constrained optimization problems. To use them, you need to learn to define constrained optimization problems. Some definitions:\n",
    "\n",
    "* An objective defines either a sum-of-square cost term, or an equality constraint, or an inequality constraint in the optimization problem. An objective is defined by its type and its feature. The type can be `sos` (sum-of-squares), `eq`, or `ineq`, referring to the three cases.\n",
    "* A feature is a (differentiable mapping) from the decision variable (the full path, or robot configuration) to a feature space. If the feature space is, e.g., 3-dimensional, this defines 3 sum-of-squares terms, or 3 inequality, or 3 equality constraints, one for each dimension. For instance, the feature can be the 3-dim robot hand position in the 15th time slice of a path optimization problem. If you put an equality constraint on this feature, then this adds 3 equality constraints to the overall path optimization problem.\n",
    "* A feature is defined by the keyword for the feature map (e.g., `pos` for position), typically by a set of frame names that tell which objects we refer to (e.g., `pr2L` for the left hand of the pr2), optionally some modifiers (e.g., a scale or target, which linearly transform the feature map), and the set of configuration IDs or time slices the feature is to be computed from (e.g., `confs=[15]` if the feat is to be computed from the 15th time slice in a path optimization problem).\n",
    "* In path optimization problems, we often want to add objectives for a whole time interval rather than for a single time slice or specific configuration. E.g., avoid collisions from start to end. When adding objectives to the optimization problem we can specify whole intervals, with `times=[1., 2.]`, so that the objective is added to each configuration in this time interval.\n",
    "* Some features, especially velocity and acceleration, refer to a tuple of (consecutive) configurations. E.g., when you impose an acceleration feature, you need to specify `confs=[13, 14, 15]`. Or if you use `times=[1.,1.]`, the acceleration features is computed from the configuration that corresponds to time=1 and the two configurations *before*.\n",
    "* All kinematic feature maps (that depend on only one configuration) can be modified to become a velocity or acceleration features. E.g., the position feature map can be modified to become a velocity or acceleration feature.\n",
    "* The `sos`, `eq`, and `ineq` always refer to the feature map to be *zero*, e.g., constraining all features to be equal to zero with `eq`. This is natural for many features, esp. when they refer to differences (e.g. `posDiff` or `posRel`, which compute the relative position between two frames). However, when one aims to constrain the feature to a non-zero constant value, one can modify the objective with a `target` specification.\n",
    "* Finally, all features can be rescaled with a `scale` specification. Rescaling changes the costs that arise from `sos` objectives. Rescaling also has significant impact on the convergence behavior for `eq` and `ineq` constraints. As a guide: scale constraints so that if they *would* be treated as squared penalties (squaredPenalty optim mode, to be made accessible) convergence to reasonable approximate solutions is efficient. Then the AugLag will also converge efficiently to precise constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concrete features\n",
    "\n",
    "The currently implemented feature keywords are:\n",
    "  FS_none,\n",
    "  FS_position,\n",
    "  FS_positionDiff,\n",
    "  FS_positionRel,\n",
    "  FS_quaternion,\n",
    "  FS_quaternionDiff,\n",
    "  FS_quaternionRel,\n",
    "  FS_pose,\n",
    "  FS_poseDiff,\n",
    "  FS_poseRel,\n",
    "  FS_vectorX,\n",
    "  FS_vectorXDiff,\n",
    "  FS_vectorXRel,\n",
    "  FS_vectorY,\n",
    "  FS_vectorYDiff,\n",
    "  FS_vectorYRel,\n",
    "  FS_vectorZ,\n",
    "  FS_vectorZDiff,\n",
    "  FS_vectorZRel,\n",
    "  FS_scalarProductZ,\n",
    "  FS_gazeAt,\n",
    "  FS_accumulatedCollisions,\n",
    "  FS_jointLimits,\n",
    "  FS_distance,\n",
    "  FS_qItself,\n",
    "  FS_aboveBox,\n",
    "  FS_insideBox,\n",
    "  FS_standingAbove,\n",
    "  \n",
    "The table is a bit outdated.. The expressions in the left of the table declare features. All of these are functions of a \\emph{single} configuration---differences and accelerations can tie multiple configurations together. Arguments typically indicate objects (actually \\emph{coordinate frame identifies}), which we write as o1, o2, etc. Another typical argument is a vector (e.g., offset) interpreted in the object's coordinate frame; e.g.\\ v1=$(0,0,1)$ to indicate the object's z-axis.\n",
    "\n",
    "| feature | dim | description |\n",
    "|:---:|:---:|:---:|\n",
    "  | `pos(o1)` | 3 | 3D position of o1 in world coordinates |\n",
    "  | `posRel(o1,o2)` | 3 | 3D position of o1 in o2 coordinates |\n",
    "  | `posDiff(o1,o2)` | 3 | difference of 3D positions of o1 and o2 in world coordinates |\n",
    "  | `vec(o1,v1)` | 3 | 3D vector v1 transformed from o1 to world |\n",
    "  | `vecRel Diff(o1,v1,o2)` | 3 | ... |\n",
    "  | `prod(o1,v1,o2,v2)` | 1 | scalar product of v1 (in o1) and v2 (in o2) |\n",
    "  | `quat(o1)` | 4 | 4D quaternion of o1 in world coordinates\\footnote{There is ways to handle the invariance w.r.t.\\ quaternion sign properly.} |\n",
    "  | `quatRel Diff(o1,o2)` | 4 | ... |\n",
    "  | `pose(o1)` | 7 | 7D pose of o1 in world coordinates |\n",
    "  | `poseRel Diff(o1,o2)` | 7 | ...|\n",
    "| `dist(o1,o2)` | 1 | NEGATIVE distance between convex meshes o1 and o2, positive for penetration|\n",
    "  | `above(o1,o2)` | ? | when all negative, o1 is above (inside support of) o2 |\n",
    "  | `placed(o1,o2)` | ? | o1 is above and straightly placed on o2 |\n",
    "| `coll` | ? | when negative, nothing is colliding |\n",
    "  | `limits` | ? | when negative, all robot joint limits are ok |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of features in Inverse Kinematics\n",
    "\n",
    "Let's setup a standard configuration. (Lock the window with \"Always on Top\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/ry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libry import *\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = Configuration()\n",
    "D = K.camera()\n",
    "K.addFile('../rai-robotModels/pr2/pr2.g')\n",
    "K.addFile('../test/kitchen.g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, let's add a frame that represents goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.addFrame(\"goal\", \"\", \"shape:marker size:[.3] color:[.5 1 1]\" )\n",
    "K.setFrameState([1,.5,1,1,0,0,0], [\"goal\"])\n",
    "x0 = K.getFrameState().flatten().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `posDiff` (position difference in world coordinates) between `pr2L` (the yellow blob in the left hand) and `goal` is equal to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.setFrameState(x0)\n",
    "IK = K.komo_IK()\n",
    "IK.addObjective(type='eq', feature='positionDiff', frames=['pr2L', 'goal'])\n",
    "IK.optimize()\n",
    "IK.getConfiguration(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'Transition',\n",
       "  'scale': 1.0,\n",
       "  'sos_value': 3.6657745735746645,\n",
       "  'type': 'sos'},\n",
       " {'description': 'QuaternionNorms',\n",
       "  'scale': 3.0,\n",
       "  'sos_value': 0.0,\n",
       "  'type': 'sos'},\n",
       " {'eq_sumOfAbs': 0.0003536309427615292,\n",
       "  'feature': 'posDiff',\n",
       "  'o1': 'pr2L',\n",
       "  'o2': 'goal',\n",
       "  'scale': 10.0,\n",
       "  'type': 'eq'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IK.getReport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `posDiff` between `pr2R` and `goal` is equal to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.setFrameState(x0)\n",
    "IK = K.komo_IK()\n",
    "IK.addObjective(type='eq', feature='positionDiff', frames=['pr2R', 'goal'])\n",
    "IK.optimize()\n",
    "IK.getConfiguration(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relative position of `goal` in `pr2R` coordinates equals [0,0,-.2] (which is 20cm straight in front of the yellow blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.setFrameState(x0)\n",
    "IK = K.komo_IK()\n",
    "IK.addObjective(type='eq', feature='positionRel', frames=['goal','pr2R'], target=[0,0,-.2])\n",
    "IK.optimize()\n",
    "IK.getConfiguration(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance between `pr2R` and `pr2L` is zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.setFrameState(x0)\n",
    "IK = K.komo_IK()\n",
    "IK.addObjective(type='eq', feature='distance', frames=['pr2L','pr2R'])\n",
    "IK.optimize()\n",
    "IK.getConfiguration(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'Transition',\n",
       "  'scale': 1.0,\n",
       "  'sos_value': 0.2077689310624419,\n",
       "  'type': 'sos'},\n",
       " {'description': 'QuaternionNorms',\n",
       "  'scale': 3.0,\n",
       "  'sos_value': 0.0,\n",
       "  'type': 'sos'},\n",
       " {'eq_sumOfAbs': 0.01132489500129505,\n",
       "  'feature': 'dist',\n",
       "  'o1': 'pr2L',\n",
       "  'o2': 'pr2R',\n",
       "  'scale': 100.0,\n",
       "  'type': 'eq'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IK.getReport()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3D difference between the z-vector of `pr2R` and the z-vector of `goal`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.setFrameState(x0)\n",
    "IK = K.komo_IK()\n",
    "IK.addObjective(type='eq', feature='vectorZDiff', frames=['pr2R', 'goal'])\n",
    "IK.optimize()\n",
    "IK.getConfiguration(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scalar product between the z-vector of `pr2R` and the z-vector of `goal` is zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.setFrameState(x0)\n",
    "IK = K.komo_IK()\n",
    "IK.addObjective(type='eq', feature='scalarProductZ', frames=['pr2R', 'goal'])\n",
    "IK.optimize()\n",
    "IK.getConfiguration(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph-structured NLP\n",
    "\n",
    "We have a set $\\{x_1,..,x_n\\}$ of $n$ variables, each with domain $x_i \\in \\mathbb{R}^{d_i}$.\n",
    "\n",
    "We have a set $\\{\\phi_1,..,\\phi_K\\}$ of $K$ features, each of which is a differentiable mapping $\\phi_k: x_{\\pi_k} \\mapsto \\mathbb{R}^{D_k}$. Here $\\pi_k \\subseteq \\{1,..,n\\}$ indicates a subset of the variables, and $x_{\\pi_k}$ is the value of this subset of variables. In addition,  $\\rho_k \\in\\{\\texttt{ineq, eq, sos}\\}$ indicates for each feature whether it is an inequality, an equality, or a sum-of-square cost objective.\n",
    "\n",
    "This defines the mathematical program\n",
    "\\begin{align}\n",
    "  \\min_{x_1,..,x_n} \\sum_{k : \\rho_k=\\texttt{sos}} \\phi_k(x_{\\pi_k})^T \\phi_k(x_{\\pi_k})\n",
    "  ~\\text{s.t.}~ \\mathop\\forall_{k : \\rho_k=\\texttt{ineq}} \\phi_k(x_{\\pi_k}) \\le 0 ~,\\quad\n",
    "  \\mathop\\forall_{k : \\rho_k=\\texttt{eq}} \\phi_k(x_{\\pi_k}) = 0 ~,\\quad\n",
    "\\end{align}\n",
    "\n",
    "In summary, a graph-structured NLP is specified as a tuple $(n, \\{d_i\\}, K, \\{\\phi_k\\}, \\{\\pi_k\\}, \\{\\rho_k\\})$.\n",
    "\n",
    "Note: I assumed here that all cose features are sum-of-squares... That's not necessary, of course. But typically the most relevant case; and we only need the Jacobian $\\partial_x \\phi$ to approximate the Gauss-Newton Hessian.\n",
    "\n",
    "Note: If all features are cost objectives, then\n",
    "\\begin{align}\n",
    "  \\prod_k \\exp\\{ -  \\phi_k(x_{\\pi_k}) \\}\n",
    "\\end{align}\n",
    "defines a factor graph. If all features are actually sum-of-square\n",
    "costs and we use Gaussian belief approximations, solving the problem\n",
    "(inference, which now also is MAP, which is also minimization) can be\n",
    "tackled with Gaussian message passing, as in GTSAM. (But in principle,\n",
    "this does not exploit more structure than a sparse matrix method to\n",
    "compute Newton steps...) In this sense, a graph-structured NLP is a\n",
    "generalization of factor graphs.\n",
    "\n",
    "Note: If the structure is $k$-order Markovian (meaning that the variables $x_i$ can be sorted into a chain and cliques $\\pi_k$ contain only $k+1$  consecutive variables), then the Hessian of the Augmented Lagrangian becomes banded diagonal, and Newton steps can be computed in $O(n)$. This is what I call KOMO ($k$-order Markov Optimization). BUT FOR SMALL $n$ ONE CAN TACKLE THE PROBLEM ALSO WITHOUT THE $k$-ORDER ASSUMPTION."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic modifiers for all features: linear rescaling, difference/velocity, acceleration\n",
    "\n",
    "We assume each variable $x_i$ is a world configuration, that is, the vector of all DOFs of the world in a specific time slice.\n",
    "\n",
    "%\\paragraph{\\texttt{order} modifier: velocities and acceleration}\n",
    "\n",
    "Most features are defined as functions of a single configuration $x_i$. E.g. $\\phi(x_i)$ could be the 3D position of endeffector in configuration $x_i$. However, for such features we automatically also define the difference and ``acceleration'' as\n",
    "\\begin{align}\n",
    "  \\phi(x_1,x_2) &\\equiv \\frac{1}{\\tau}(\\phi(x_2) - \\phi(x_1)) \\\\\n",
    "  \\phi(x_1,x_2,x_3) &\\equiv \\frac{1}{\\tau^2}(\\phi(x_1) + \\phi(x_3) - 2 \\phi(x_2))\n",
    "\\end{align}\n",
    "When in the specification such a $\\phi$ is indicated to depend on two configurations, it automatically means that we impose an objective on the velocity/difference; if on three configurations, then we impose an objective on the acceleration.\n",
    "\n",
    "%\\paragraph{\\texttt{scale, target} modifiers: linear rescaling}\n",
    "\n",
    "The (in)equalities always refer to zero. To constrain $\\phi(x) = \\textit{target}$ you can modify any defined feature by specifying a \\texttt{target} and/or \\texttt{scale}, which implies\n",
    "\\begin{align}\n",
    "  \\tilde \\phi(x) \\gets \\texttt{scale} \\cdot (\\phi(x) - \\texttt{target})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Specification of a robot problem\n",
    "\n",
    "We have two configurations $x_1, x_2$; here is a specification of features that define the NLP for grasping an object in $x_1$ and placing it on a tray in $x_2$:\n",
    "```\n",
    "(1,2): { sos, trans, scale:0.1 }\n",
    "(1,2): { eq, pose(object, hand) }\n",
    "  (1):   { eq, dist(object, hand) }\n",
    "  (1):   { ineq, coll }\n",
    "  (2):   { ineq, coll }\n",
    "  (2):   { eq, dist(object, tray) }\n",
    "  (2):   { ineq, above(object, tray) }\n",
    "  (2):   { eq, vec(object, (0,0,1)), target:(0,0,1) }\n",
    "```\n",
    "Here, every tuple $(i,j)$ indicates an objective that depends on variables $x_i,x_j$. The @{..}@ desribes the objective. The objectives read:\n",
    "* We penalize configuration difference between $x_1, x_2$ with a weak sum-of-square term\n",
    "* The relative pose of object in hand has zero difference between configurations $x_1, x_2$\n",
    "* The distance between object and hand is zero in configuration $x_1$\n",
    "* There are no collisions in configuration $x_1$\n",
    "* There are no collisions in configuration $x_2$\n",
    "* The object touches tray (distance=zero) in config 2\n",
    "* The object is above the tray in config 2\n",
    "* The object's z-axis equals the world z-axis in config 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
